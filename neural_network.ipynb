{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d6592c3",
   "metadata": {},
   "source": [
    "# More Models!\n",
    "\n",
    "Now let's try to come up with the best model we can for predicting expected goals! In this section, we will try several different models, some feature selection methods and hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c40d105",
   "metadata": {},
   "source": [
    "## Neural Network\n",
    "\n",
    "Firstly, we implemented a neural network with the keras library. After tuning the hyperparameters, we have come to the conclusion that the best results were found with the SGD optimizer (learning rate of 0.0001) and with one hidden layer containing 16 neurons (relu activation function and binary cross-entropy as the loss function). It trains on 50 epochs with an early stopping that checks if the model hasn't improved for the last 10 epochs (with a minimum of 10 epochs done already) and keeps the wiehgts of the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6620a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for preprocessing\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from utils.model_utils import *\n",
    "from neural_network import *\n",
    "\n",
    "# for model training\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# for plotting\n",
    "from utils.plot_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327bf5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('advanced_models_data.csv')\n",
    "\n",
    "# Preprocess data\n",
    "X_res_scaled, y_res = preprocess_neural_network_rfc(df)\n",
    "\n",
    "# Split the data into training, validation and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res_scaled, y_res, test_size=0.2, shuffle=True)\n",
    "X_train, y_train = balance_data(X_train, y_train)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, shuffle=True)  # 0.25 x 0.8 = 0.2\n",
    "\n",
    "# train model\n",
    "model, history = train(X_train, y_train, X_val, y_val)\n",
    "\n",
    "# save model\n",
    "model.save(\"models/neural_network.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b71f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23821087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "plt.savefig(f'model_accuracy_corr.png')\n",
    "\n",
    "\n",
    "# plot the training loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "plt.savefig(f'model_loss_corr.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2479c640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test accuracy: {test_accuracy * 100:.2f}%')\n",
    "\n",
    "preds = np.round(model.predict(X_test), 0)\n",
    "\n",
    "# confusion matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "print(f1_score(y_test, preds, average=\"macro\"))\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_test, preds)).plot()\n",
    "plt.show()\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304043f2",
   "metadata": {},
   "source": [
    "### Plotting the ROC curve, goal rate vs probability percentile, cumulative proportion of goals vs probability percentile, and the reliability curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b872277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve\n",
    "plot_roc_curve_nn(predictions, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03b78de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the probability predictions 1D\n",
    "predictions = predictions.flatten()\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26df7e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# goal rate vs probability percentile\n",
    "shot_prob_model_percentile_nn(predictions, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8db5296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cumulative proportion of goals vs probability percentile\n",
    "plot_cumulative_sum_nn(predictions, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b197ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reliability curve\n",
    "plot_calibration_curve_nn(predictions, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c1a7eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
